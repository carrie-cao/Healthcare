{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "[VGG16](https://neurohive.io/en/popular-networks/vgg16/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50 \n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "valid_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 validated image filenames belonging to 2 classes.\n",
      "Found 6 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_idg = ImageDataGenerator(rescale=1. / 255.0,\n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.1, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=20, \n",
    "                              shear_range = 0.1,\n",
    "                              zoom_range=0.1)\n",
    "\n",
    "train_gen = train_idg.flow_from_dataframe(dataframe=train_df, \n",
    "                                         directory=None, \n",
    "                                         x_col = 'img_path',\n",
    "                                         y_col = 'class',\n",
    "                                         class_mode = 'binary',\n",
    "                                         target_size = IMG_SIZE, \n",
    "                                         batch_size = 9\n",
    "                                         )\n",
    "\n",
    "# the validation data should not be augmented\n",
    "val_idg = ImageDataGenerator(rescale=1. / 255.0\n",
    "                                 )\n",
    "\n",
    "val_gen = val_idg.flow_from_dataframe(dataframe=valid_df, \n",
    "                                         directory=None, \n",
    "                                         x_col = 'img_path',\n",
    "                                         y_col = 'class',\n",
    "                                         class_mode = 'binary',\n",
    "                                         target_size = IMG_SIZE, \n",
    "                                         batch_size = 6) ## We've only been provided with 6 validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull a single large batch of random validation data for testing after each epoch\n",
    "testX, testY = val_gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in VGG16 with pre-trained ImageNet weights: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=True, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_pool False\n",
      "block5_conv1 False\n",
      "block5_conv2 False\n",
      "block5_conv3 True\n",
      "block5_pool True\n"
     ]
    }
   ],
   "source": [
    "transfer_layer = model.get_layer('block5_pool')\n",
    "vgg_model = Model(inputs=model.input,\n",
    "                   outputs=transfer_layer.output)\n",
    "\n",
    "## choose the layers of VGG16 want to fine-tune, freeze all but the last convolutional layer\n",
    "for layer in vgg_model.layers[0:17]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Program\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Program\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.8464 - binary_accuracy: 0.3500 - val_loss: 0.7276 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.6863 - binary_accuracy: 0.5000 - val_loss: 0.6982 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.6058 - binary_accuracy: 0.6500 - val_loss: 0.6569 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.5689 - binary_accuracy: 0.7500 - val_loss: 0.6337 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.4147 - binary_accuracy: 0.9500 - val_loss: 0.6281 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28200128e88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "\n",
    "# Add the convolutional part of the VGG16 model \n",
    "new_model.add(vgg_model)\n",
    "\n",
    "# Flatten the output of the VGG16 model because it is from convolutional layer.\n",
    "new_model.add(Flatten())\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# This is for combining features that the VGG16 model has recognized in the image.\n",
    "new_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "## Set our optimizer, loss function, and learning rate\n",
    "optimizer = Adam(lr=1e-4)\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['binary_accuracy']\n",
    "\n",
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "## run a single epoch to check:\n",
    "new_model.fit_generator(train_gen, \n",
    "                                  validation_data = (testX, testY), \n",
    "                                  epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 0.7990 - binary_accuracy: 0.4000 - val_loss: 0.7567 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.5960 - binary_accuracy: 0.5500 - val_loss: 0.6951 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.4884 - binary_accuracy: 0.7000 - val_loss: 0.6823 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.5533 - binary_accuracy: 0.7500 - val_loss: 0.4943 - val_binary_accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.4602 - binary_accuracy: 0.8000 - val_loss: 0.6017 - val_binary_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282003c46c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "\n",
    "new_model.add(vgg_model)\n",
    "\n",
    "new_model.add(Flatten())\n",
    "\n",
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "new_model.fit_generator(train_gen, \n",
    "                                  validation_data = (testX, testY), \n",
    "                                  epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dropout and another fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 269ms/step - loss: 0.6668 - binary_accuracy: 0.7000 - val_loss: 0.6930 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.7959 - binary_accuracy: 0.4500 - val_loss: 0.6849 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.8475 - binary_accuracy: 0.4500 - val_loss: 0.6646 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.6960 - binary_accuracy: 0.4000 - val_loss: 0.5844 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.8034 - binary_accuracy: 0.6500 - val_loss: 0.6340 - val_binary_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28201db6bc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(vgg_model)\n",
    "new_model.add(Flatten())\n",
    "\n",
    "# Add a dropout-layer which may prevent overfitting \n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer\n",
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer \n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "new_model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add a dropout-layer \n",
    "new_model.add(Dropout(0.5))\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer\n",
    "new_model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Add a dense (aka. fully-connected) layer.\n",
    "# Change the activation function to sigmoid \n",
    "# so output of the last layer is in the range of [0,1] \n",
    "new_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "## run a single epoch \n",
    "new_model.fit_generator(train_gen, \n",
    "                                  validation_data = (testX, testY), \n",
    "                                  epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " The last architecture seemed to show more stable than the second. Likely due to the fact that added Dropout. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
